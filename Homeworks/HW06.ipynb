{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW06: ML and Causal Inference (due November 9th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Double Machine learning with Lasso\n",
    "\n",
    "In this exercise you will investigate a research question similar to the one in HW02. Namely, what is the effect of being in a Union on wages? You will use the same data as in HW02 (description of the variables can be found [here](https://rdrr.io/rforge/sampleSelection/man/nlswork.html)). Although, here instead of just including controls, you will estimate the effect of union membership on wages using double Lasso.\n",
    "\n",
    "The regression of reference is the following: \n",
    "\n",
    "$$ln\\_wage_i = \\beta_0 + \\beta_1 union_i +\\varepsilon_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (NLSY)\n",
    "df = pd.read_stata('http://www.stata-press.com/data/r16/nlswork.dta')\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idcode</th>\n",
       "      <th>year</th>\n",
       "      <th>birth_yr</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>msp</th>\n",
       "      <th>nev_mar</th>\n",
       "      <th>grade</th>\n",
       "      <th>collgrad</th>\n",
       "      <th>not_smsa</th>\n",
       "      <th>...</th>\n",
       "      <th>south</th>\n",
       "      <th>ind_code</th>\n",
       "      <th>occ_code</th>\n",
       "      <th>union</th>\n",
       "      <th>wks_ue</th>\n",
       "      <th>ttl_exp</th>\n",
       "      <th>tenure</th>\n",
       "      <th>hours</th>\n",
       "      <th>wks_work</th>\n",
       "      <th>ln_wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>black</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.256410</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.589977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>25.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.775641</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.778681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>51</td>\n",
       "      <td>28.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.294872</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.551715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>33.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.160256</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.614172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>35.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.987180</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>45.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.536374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idcode  year  birth_yr   age   race  msp  nev_mar  grade  collgrad  \\\n",
       "0       1    72        51  20.0  black  1.0      0.0   12.0         0   \n",
       "1       1    77        51  25.0  black  0.0      0.0   12.0         0   \n",
       "2       1    80        51  28.0  black  0.0      0.0   12.0         0   \n",
       "3       1    85        51  33.0  black  0.0      0.0   12.0         0   \n",
       "4       1    87        51  35.0  black  0.0      0.0   12.0         0   \n",
       "\n",
       "   not_smsa  ...  south  ind_code  occ_code  union  wks_ue   ttl_exp  \\\n",
       "0       0.0  ...    0.0       4.0       6.0    1.0     0.0  2.256410   \n",
       "1       0.0  ...    0.0      12.0       8.0    0.0     0.0  3.775641   \n",
       "2       0.0  ...    0.0       5.0       6.0    1.0     0.0  5.294872   \n",
       "3       0.0  ...    0.0       5.0       6.0    1.0     0.0  7.160256   \n",
       "4       0.0  ...    0.0       5.0       6.0    1.0     0.0  8.987180   \n",
       "\n",
       "     tenure  hours  wks_work   ln_wage  \n",
       "0  0.916667   40.0      51.0  1.589977  \n",
       "1  1.500000   32.0      52.0  1.778681  \n",
       "2  1.833333   45.0      75.0  2.551715  \n",
       "3  1.916667   42.0      97.0  2.614172  \n",
       "4  3.916667   45.0      95.0  2.536374  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y = df['ln_wage']\n",
    "D = df['union']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>ln_wage</td>     <th>  R-squared:         </th> <td>   0.052</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.052</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   741.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>4.56e-159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:29:09</td>     <th>  Log-Likelihood:    </th> <td> -8266.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 13452</td>      <th>  AIC:               </th> <td>1.654e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 13450</td>      <th>  BIC:               </th> <td>1.655e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.6564</td> <td>    0.004</td> <td>  377.147</td> <td> 0.000</td> <td>    1.648</td> <td>    1.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>union</th>     <td>    0.2502</td> <td>    0.009</td> <td>   27.238</td> <td> 0.000</td> <td>    0.232</td> <td>    0.268</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>425.572</td> <th>  Durbin-Watson:     </th> <td>   1.032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 895.660</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.205</td>  <th>  Prob(JB):          </th> <td>3.24e-195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.196</td>  <th>  Cond. No.          </th> <td>    2.53</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &     ln\\_wage     & \\textbf{  R-squared:         } &     0.052   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.052   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     741.9   \\\\\n",
       "\\textbf{Date:}             & Sat, 04 Nov 2023 & \\textbf{  Prob (F-statistic):} & 4.56e-159   \\\\\n",
       "\\textbf{Time:}             &     18:29:09     & \\textbf{  Log-Likelihood:    } &   -8266.7   \\\\\n",
       "\\textbf{No. Observations:} &       13452      & \\textbf{  AIC:               } & 1.654e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &       13450      & \\textbf{  BIC:               } & 1.655e+04   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       1.6564  &        0.004     &   377.147  &         0.000        &        1.648    &        1.665     \\\\\n",
       "\\textbf{union}     &       0.2502  &        0.009     &    27.238  &         0.000        &        0.232    &        0.268     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 425.572 & \\textbf{  Durbin-Watson:     } &     1.032  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   895.660  \\\\\n",
       "\\textbf{Skew:}          &   0.205 & \\textbf{  Prob(JB):          } & 3.24e-195  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.196 & \\textbf{  Cond. No.          } &      2.53  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                ln_wage   R-squared:                       0.052\n",
       "Model:                            OLS   Adj. R-squared:                  0.052\n",
       "Method:                 Least Squares   F-statistic:                     741.9\n",
       "Date:                Sat, 04 Nov 2023   Prob (F-statistic):          4.56e-159\n",
       "Time:                        18:29:09   Log-Likelihood:                -8266.7\n",
       "No. Observations:               13452   AIC:                         1.654e+04\n",
       "Df Residuals:                   13450   BIC:                         1.655e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.6564      0.004    377.147      0.000       1.648       1.665\n",
       "union          0.2502      0.009     27.238      0.000       0.232       0.268\n",
       "==============================================================================\n",
       "Omnibus:                      425.572   Durbin-Watson:                   1.032\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              895.660\n",
       "Skew:                           0.205   Prob(JB):                    3.24e-195\n",
       "Kurtosis:                       4.196   Cond. No.                         2.53\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "## Run the regression written above\n",
    "res = smf.ols(\"ln_wage ~ union\", df).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What could be potential sources of bias (i.e. confounders)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age, grade, collgrad could be potential confounders. For instance, age direclty impact the wage of the individual. More experienced individuals earn more. Also, as people are older they had more time to join unions and time trends can affect the union probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idcode</th>\n",
       "      <th>year</th>\n",
       "      <th>birth_yr</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>msp</th>\n",
       "      <th>nev_mar</th>\n",
       "      <th>grade</th>\n",
       "      <th>collgrad</th>\n",
       "      <th>not_smsa</th>\n",
       "      <th>c_city</th>\n",
       "      <th>south</th>\n",
       "      <th>ind_code</th>\n",
       "      <th>occ_code</th>\n",
       "      <th>union</th>\n",
       "      <th>wks_ue</th>\n",
       "      <th>ttl_exp</th>\n",
       "      <th>tenure</th>\n",
       "      <th>hours</th>\n",
       "      <th>wks_work</th>\n",
       "      <th>ln_wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>black</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.256410</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.589977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>25.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.775641</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.778681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>51</td>\n",
       "      <td>28.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.294872</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.551715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>33.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.160256</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.614172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>35.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.987180</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>45.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.536374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idcode  year  birth_yr   age   race  msp  nev_mar  grade  collgrad  \\\n",
       "0       1    72        51  20.0  black  1.0      0.0   12.0         0   \n",
       "1       1    77        51  25.0  black  0.0      0.0   12.0         0   \n",
       "2       1    80        51  28.0  black  0.0      0.0   12.0         0   \n",
       "3       1    85        51  33.0  black  0.0      0.0   12.0         0   \n",
       "4       1    87        51  35.0  black  0.0      0.0   12.0         0   \n",
       "\n",
       "   not_smsa  c_city  south  ind_code  occ_code  union  wks_ue   ttl_exp  \\\n",
       "0       0.0     1.0    0.0       4.0       6.0    1.0     0.0  2.256410   \n",
       "1       0.0     1.0    0.0      12.0       8.0    0.0     0.0  3.775641   \n",
       "2       0.0     1.0    0.0       5.0       6.0    1.0     0.0  5.294872   \n",
       "3       0.0     1.0    0.0       5.0       6.0    1.0     0.0  7.160256   \n",
       "4       0.0     0.0    0.0       5.0       6.0    1.0     0.0  8.987180   \n",
       "\n",
       "     tenure  hours  wks_work   ln_wage  \n",
       "0  0.916667   40.0      51.0  1.589977  \n",
       "1  1.500000   32.0      52.0  1.778681  \n",
       "2  1.833333   45.0      75.0  2.551715  \n",
       "3  1.916667   42.0      97.0  2.614172  \n",
       "4  3.916667   45.0      95.0  2.536374  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in X with all predictors that are not colliders\n",
    "# wage and union has a certain impact on the wks_work, hours, wks_ue, occ_code and ind_code\n",
    "X_cat = df[[\"year\", \"race\", 'msp', 'nev_mar', 'collgrad', 'not_smsa', 'c_city', 'south', 'union']]\n",
    "X_cont = df[[\"age\", \"birth_yr\", \"ttl_exp\", \"tenure\", \"grade\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "X_cat_columns = X_cat.columns\n",
    "X_cat = encoder.fit_transform(X_cat)\n",
    "X_cat = X_cat.astype('float32')\n",
    "X_cat = pd.DataFrame(X_cat, columns=X_cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all continuous variable in X to variance one\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_cont = pd.DataFrame(StandardScaler().fit_transform(X_cont), columns=X_cont.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>race</th>\n",
       "      <th>msp</th>\n",
       "      <th>nev_mar</th>\n",
       "      <th>collgrad</th>\n",
       "      <th>not_smsa</th>\n",
       "      <th>c_city</th>\n",
       "      <th>south</th>\n",
       "      <th>union</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_yr</th>\n",
       "      <th>ttl_exp</th>\n",
       "      <th>tenure</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.590810</td>\n",
       "      <td>0.953870</td>\n",
       "      <td>-1.024537</td>\n",
       "      <td>-0.671341</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.811221</td>\n",
       "      <td>0.953870</td>\n",
       "      <td>-0.679933</td>\n",
       "      <td>-0.516603</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.343467</td>\n",
       "      <td>0.953870</td>\n",
       "      <td>-0.335330</td>\n",
       "      <td>-0.428182</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>0.953870</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>-0.406077</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747959</td>\n",
       "      <td>0.953870</td>\n",
       "      <td>0.502189</td>\n",
       "      <td>0.124452</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13447</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280205</td>\n",
       "      <td>-1.354124</td>\n",
       "      <td>-1.063796</td>\n",
       "      <td>-0.361866</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13448</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>-1.354124</td>\n",
       "      <td>-0.855870</td>\n",
       "      <td>-0.118707</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13449</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.215712</td>\n",
       "      <td>-1.354124</td>\n",
       "      <td>0.295717</td>\n",
       "      <td>1.207614</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13450</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.527548</td>\n",
       "      <td>-1.354124</td>\n",
       "      <td>0.522545</td>\n",
       "      <td>-0.914500</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13451</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.995302</td>\n",
       "      <td>-1.354124</td>\n",
       "      <td>0.867149</td>\n",
       "      <td>-0.008180</td>\n",
       "      <td>-0.287475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13452 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  race  msp  nev_mar  collgrad  not_smsa  c_city  south  union  \\\n",
       "0       2.0   0.0  1.0      0.0       0.0       0.0     1.0    0.0    1.0   \n",
       "1       4.0   0.0  0.0      0.0       0.0       0.0     1.0    0.0    0.0   \n",
       "2       6.0   0.0  0.0      0.0       0.0       0.0     1.0    0.0    1.0   \n",
       "3       9.0   0.0  0.0      0.0       0.0       0.0     1.0    0.0    1.0   \n",
       "4      10.0   0.0  0.0      0.0       0.0       0.0     0.0    0.0    1.0   \n",
       "...     ...   ...  ...      ...       ...       ...     ...    ...    ...   \n",
       "13447   4.0   0.0  1.0      0.0       0.0       0.0     1.0    1.0    0.0   \n",
       "13448   5.0   0.0  1.0      0.0       0.0       0.0     1.0    1.0    1.0   \n",
       "13449   8.0   0.0  0.0      0.0       0.0       0.0     1.0    1.0    1.0   \n",
       "13450   9.0   0.0  0.0      0.0       0.0       0.0     1.0    1.0    1.0   \n",
       "13451  11.0   0.0  0.0      0.0       0.0       0.0     1.0    1.0    1.0   \n",
       "\n",
       "            age  birth_yr   ttl_exp    tenure     grade  \n",
       "0     -1.590810  0.953870 -1.024537 -0.671341 -0.287475  \n",
       "1     -0.811221  0.953870 -0.679933 -0.516603 -0.287475  \n",
       "2     -0.343467  0.953870 -0.335330 -0.428182 -0.287475  \n",
       "3      0.436123  0.953870  0.087792 -0.406077 -0.287475  \n",
       "4      0.747959  0.953870  0.502189  0.124452 -0.287475  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "13447  0.280205 -1.354124 -1.063796 -0.361866 -0.287475  \n",
       "13448  0.436123 -1.354124 -0.855870 -0.118707 -0.287475  \n",
       "13449  1.215712 -1.354124  0.295717  1.207614 -0.287475  \n",
       "13450  1.527548 -1.354124  0.522545 -0.914500 -0.287475  \n",
       "13451  1.995302 -1.354124  0.867149 -0.008180 -0.287475  \n",
       "\n",
       "[13452 rows x 14 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join all Xs\n",
    "X = pd.merge(X_cat, X_cont, left_index=True, right_index=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, D_train, D_test, y_train, y_test = train_test_split(X, D, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The econml library allows us to distinguish between two different types of confounders represented by a matrix *X* and a matrix *W*.\n",
    "\n",
    "- *X* : confounders that interact with the treatment. we will be able to calculate heterogeneous treatment effects using them.\n",
    "- *W*: confounders that don´t interact with the treatment. this can be a very high-dimensional matrix.\n",
    "\n",
    "To be precise our model with these two types of confounders looks as follows:\n",
    "\n",
    "$$ Y = D \\cdot g(X) + W +  e $$\n",
    "\n",
    "Where D is our treatment variable. In this first demonstration of double machine learning we will not focus on heterogeneous treatment effects and thus we will have all of our confounders as *W*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DML model with double LASSO\n",
    "\n",
    "from econml.dml import  LinearDML\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "\n",
    "# LinearDML: https://econml.azurewebsites.net/_autosummary/econml.dml.LinearDML.html\n",
    "est = LinearDML(model_y=LassoCV(),          # Y\n",
    "                model_t=LogisticRegressionCV(), # D    \n",
    "                discrete_treatment=True,\n",
    "                linear_first_stages=True,\n",
    "                cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.dml.dml.LinearDML at 0x1a274749d00>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "est.fit(y_train, D_train, X=None, W=X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th> <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.005</td>      <td>0.022</td> <td>0.229</td>  <td>0.819</td>  <td>-0.039</td>    <td>0.049</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                      \n",
       "===================================================================\n",
       "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
       "-------------------------------------------------------------------\n",
       "cate_intercept          0.005  0.022 0.229  0.819   -0.039    0.049\n",
       "-------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a summary\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the estimates form this and the previous regression. How do these change?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Prior to the regression, the union was 25% positevely correlated with the wage. After the double machine learning, we concluded that the union was not correlated to the wage since the err is more than 2 times the coeff and the confidence interval contains 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the coefficient from the double ml approach. Can it be interpreted as causal?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "No, it cannot be interpreted as causal like mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Heterogenous Treatment Effects with double Lasso\n",
    "\n",
    "This exercise will be a simple extension of exercise 1. We just want to estimate a CausalForestDML model where we can analyze heterogeneous treatment effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CausalForestDML: https://econml.azurewebsites.net/_autosummary/econml.dml.CausalForestDML.html\n",
    "from econml.dml import CausalForestDML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model. check the documentation, you might need to specify less things than you think...\n",
    "est2 = CausalForestDML(model_y='auto',\n",
    "                       model_t='auto',\n",
    "                       discrete_treatment=True,\n",
    "                       n_estimators=100,\n",
    "                       max_depth=30,\n",
    "                       cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.dml.causal_forest.CausalForestDML at 0x1a27445c640>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune the model\n",
    "est2.tune(y_train, D_train, X=X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.dml.causal_forest.CausalForestDML at 0x1a27445c640>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "est2.fit(y_train, D_train, X=X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population summary results are available only if `cache_values=True` at fit time!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Doubly Robust ATE on Training Data Results</caption>\n",
       "<tr>\n",
       "   <td></td>   <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATE</th>     <td>-0.033</td>      <td>0.006</td> <td>-5.377</td>   <td>0.0</td>   <td>-0.045</td>   <td>-0.021</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Doubly Robust ATT(T=0) on Training Data Results</caption>\n",
       "<tr>\n",
       "   <td></td>   <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATT</th>     <td>-0.016</td>      <td>0.007</td> <td>-2.329</td>  <td>0.02</td>    <td>-0.03</td>   <td>-0.003</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Doubly Robust ATT(T=1) on Training Data Results</caption>\n",
       "<tr>\n",
       "   <td></td>   <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATT</th>     <td>-0.091</td>      <td>0.013</td> <td>-6.848</td>   <td>0.0</td>   <td>-0.117</td>   <td>-0.065</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "        Doubly Robust ATE on Training Data Results       \n",
       "=========================================================\n",
       "    point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "---------------------------------------------------------\n",
       "ATE         -0.033  0.006 -5.377    0.0   -0.045   -0.021\n",
       "     Doubly Robust ATT(T=0) on Training Data Results     \n",
       "=========================================================\n",
       "    point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "---------------------------------------------------------\n",
       "ATT         -0.016  0.007 -2.329   0.02    -0.03   -0.003\n",
       "     Doubly Robust ATT(T=1) on Training Data Results     \n",
       "=========================================================\n",
       "    point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "---------------------------------------------------------\n",
       "ATT         -0.091  0.013 -6.848    0.0   -0.117   -0.065\n",
       "---------------------------------------------------------\n",
       "\"\"\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary\n",
    "est2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the feature importance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(est2.cate_feature_names(), est2.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
